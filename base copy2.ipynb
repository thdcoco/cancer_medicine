{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 암환자 유전체 데이터 기반 암종 분류 AI 모델 개발\n",
    "\n",
    "\n",
    "- '2024 생명연구자원 AI활용 경진대회'는 바이오 데이터를 기반으로 한 AI 기술의 문제 해결 능력을 탐구하는 것을 목표로 합니다. <br>이 대회는 바이오 분야에서 AI 활용의 저변을 확대하고, 복잡한 바이오 데이터를 효율적으로 분석 및 해석할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br><br>\n",
    "- 본 대회의 구체적인 과제는 암환자 유전체 데이터의 변이 정보를 활용하여 암종을 분류하는 AI 모델을 개발하는 것입니다. <br>참가자들은 제공된 학습 데이터셋(암환자 유전체 변이 정보)을 사용하여 특정 변이 정보를 바탕으로 암종을 정확하게 분류할 수 있는 AI 알고리즘을 개발해야 합니다. <br><br>\n",
    "- 이 대회의 궁극적인 목적은 바이오 데이터의 활용도를 높이고, 바이오 분야에서 AI 기술의 적용 가능성을 극대화하며, 인공지능 기술이 실제 바이오 의료 문제 해결에 어떻게 기여할 수 있는지 탐구하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 레이블: ACC, 변환된 숫자: 0\n",
      "원래 레이블: BLCA, 변환된 숫자: 1\n",
      "원래 레이블: BRCA, 변환된 숫자: 2\n",
      "원래 레이블: CESC, 변환된 숫자: 3\n",
      "원래 레이블: COAD, 변환된 숫자: 4\n",
      "원래 레이블: DLBC, 변환된 숫자: 5\n",
      "원래 레이블: GBMLGG, 변환된 숫자: 6\n",
      "원래 레이블: HNSC, 변환된 숫자: 7\n",
      "원래 레이블: KIPAN, 변환된 숫자: 8\n",
      "원래 레이블: KIRC, 변환된 숫자: 9\n",
      "원래 레이블: LAML, 변환된 숫자: 10\n",
      "원래 레이블: LGG, 변환된 숫자: 11\n",
      "원래 레이블: LIHC, 변환된 숫자: 12\n",
      "원래 레이블: LUAD, 변환된 숫자: 13\n",
      "원래 레이블: LUSC, 변환된 숫자: 14\n",
      "원래 레이블: OV, 변환된 숫자: 15\n",
      "원래 레이블: PAAD, 변환된 숫자: 16\n",
      "원래 레이블: PCPG, 변환된 숫자: 17\n",
      "원래 레이블: PRAD, 변환된 숫자: 18\n",
      "원래 레이블: SARC, 변환된 숫자: 19\n",
      "원래 레이블: SKCM, 변환된 숫자: 20\n",
      "원래 레이블: STES, 변환된 숫자: 21\n",
      "원래 레이블: TGCT, 변환된 숫자: 22\n",
      "원래 레이블: THCA, 변환된 숫자: 23\n",
      "원래 레이블: THYM, 변환된 숫자: 24\n",
      "원래 레이블: UCEC, 변환된 숫자: 25\n"
     ]
    }
   ],
   "source": [
    "# SUBCLASS 가 범주형이기 때문에 LabelEncoder 사용\n",
    "le_subclass = LabelEncoder()\n",
    "train['SUBCLASS'] = le_subclass.fit_transform(train['SUBCLASS'])\n",
    "\n",
    "# 변환된 레이블 확인\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"원래 레이블: {label}, 변환된 숫자: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train = train.drop(columns=\"SUBCLASS\"), train[\"SUBCLASS\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.concat((X_train, y_train), axis=1)\n",
    "val_all = pd.concat((X_val, y_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x 의 경우도 범주형으로 구성되어 있어, 알맞은 인코딩 필요\n",
    "X = train_all.drop(columns=['SUBCLASS', 'ID'])\n",
    "y_subclass = train_all['SUBCLASS']\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_encoded = X.copy()\n",
    "X_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.drop(columns=['ID'])\n",
    "test_X_encoded = test_X.copy()\n",
    "test_X_encoded[categorical_columns] = ordinal_encoder.transform(test_X[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_all.drop(columns=['SUBCLASS', 'ID'])\n",
    "val_y_encoded = val_all['SUBCLASS']\n",
    "\n",
    "\n",
    "val_x_encoded = X_val.copy()\n",
    "val_x_encoded[categorical_columns] = ordinal_encoder.transform(X_val[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Random State: 0 ##\n",
      "\n",
      "######################################## 폴드 1 / 10 ########################################\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[5, 9, 16, 17, 18, 22, 31, 33, 35, 41, 44, 50, 54, 56, 68, 69, 86, 93, 102, 104, 108, 116, 122, 124, 136, 138, 140, 149, 154, 158, 164, 168, 169, 177, 179, 180, 182, 188, 191, 192, 196, 210, 211, 214, 216, 218, 219, 228, 231, 234, 239, 241, 245, 256, 263, 282, 296, 309, 320, 331, 332, 333, 339, 341, 342, 350, 359, 362, 363, 370, 373, 374, 376, 385, 388, 401, 425, 430, 436, 439, 446, 450, 454, 471, 473, 479, 484, 490, 496, 497, 503, 505, 511, 517, 532, 533, 536, 538, 545, 550, 552, 553, 554, 561, 564, 568, 580, 601, 605, 619, 629, 630, 644, 652, 653, 668, 686, 698, 700, 706, 713, 721, 732, 745, 755, 765, 769, 786, 804, 810, 835, 836, 838, 839, 841, 843, 849, 853, 854, 871, 877, 878, 893, 896, 897, 926, 927, 930, 935, 946, 952, 960, 964, 972, 977, 983, 989, 994, 998, 1007, 1011, 1028, 1030, 1032, 1034, 1041, 1045, 1055, 1066, 1075, 1076, 1079, 1082, 1094, 1104, 1108, 1122, 1140, 1141, 1154, 1155, 1160, 1161, 1163, 1164, 1166, 1169, 1176, 1178, 1179, 1181, 1189, 1217, 1218, 1222, 1229, 1233, 1236, 1240, 1244, 1245, 1246, 1260, 1273, 1277, 1279, 1280, 1284, 1285, 1286, 1287, 1288, 1297, 1298, 1301, 1319, 1334, 1345, 1348, 1374, 1376, 1384, 1385, 1388, 1396, 1397, 1403, 1405, 1408, 1410, 1411, 1415, 1417, 1423, 1429, 1433, 1437, 1439, 1447, 1448, 1455, 1461, 1463, 1464, 1479, 1487, 1488, 1489, 1491, 1492, 1493, 1512, 1530, 1532, 1535, 1547, 1559, 1560, 1561, 1565, 1569, 1575, 1576, 1579, 1588, 1589, 1597, 1621, 1623, 1624, 1634, 1636, 1637, 1644, 1646, 1647, 1648, 1651, 1653, 1665, 1670, 1671, 1674, 1680, 1691, 1694, 1695, 1718, 1731, 1735, 1736, 1738, 1742, 1759, 1760, 1771, 1772, 1773, 1776, 1786, 1794, 1799, 1808, 1825, 1829, 1834, 1836, 1841, 1843, 1847, 1852, 1872, 1876, 1877, 1881, 1887, 1891, 1900, 1907, 1908, 1913, 1921, 1929, 1932, 1942, 1947, 1948, 1950, 1954, 1961, 1971, 1972, 1975, 1976, 1977, 1978, 1999, 2001, 2003, 2008, 2010, 2014, 2032, 2041, 2046, 2047, 2049, 2050, 2062, 2069, 2074, 2080, 2084, 2091, 2096, 2097, 2098, 2100, 2108, 2112, 2117, 2130, 2141, 2159, 2163, 2166, 2169, 2176, 2179, 2187, 2188, 2197, 2202, 2218, 2219, 2228, 2236, 2237, 2245, 2246, 2254, 2262, 2277, 2279, 2282, 2288, 2291, 2297, 2298, 2305, 2306, 2310, 2325, 2330, 2343, 2356, 2361, 2366, 2372, 2379, 2397, 2399, 2402, 2405, 2407, 2408, 2421, 2425, 2434, 2438, 2442, 2445, 2451, 2487, 2491, 2497, 2500, 2505, 2508, 2512, 2522, 2529, 2531, 2536, 2542, 2543, 2544, 2548, 2549, 2567, 2579, 2592, 2596, 2599, 2605, 2607, 2620, 2625, 2630, 2633, 2639, 2659, 2660, 2662, 2665, 2667, 2671, 2679, 2683, 2689, 2697, 2702, 2722, 2725, 2726, 2742, 2745, 2748, 2754, 2764, 2765, 2768, 2776, 2780, 2783, 2788, 2791, 2800, 2812, 2826, 2832, 2836, 2839, 2844, 2851, 2866, 2876, 2877, 2878, 2882, 2885, 2889, 2898, 2902, 2903, 2904, 2905, 2914, 2930, 2932, 2936, 2938, 2945, 2948, 2951, 2952, 2953, 2955, 2968, 2985, 2989, 2996, 3001, 3002, 3017, 3018, 3021, 3022, 3047, 3051, 3058, 3061, 3062, 3065, 3067, 3069, 3071, 3086, 3093, 3096, 3099, 3110, 3116, 3121, 3122, 3129, 3131, 3134, 3138, 3140, 3142, 3144, 3146, 3147, 3163, 3168, 3189, 3194, 3197, 3207, 3211, 3215, 3216, 3220, 3224, 3230, 3233, 3238, 3249, 3253, 3257, 3262, 3267, 3268, 3277, 3282, 3283, 3288, 3298, 3300, 3301, 3314, 3323, 3325, 3343, 3345, 3346, 3355, 3366, 3369, 3370, 3376, 3377, 3378, 3385, 3393, 3400, 3402, 3403, 3405, 3419, 3436, 3437, 3442, 3443, 3453, 3457, 3468, 3474, 3485, 3498, 3499, 3501, 3508, 3511, 3517, 3519, 3523, 3528, 3532, 3536, 3547, 3548, 3550, 3551, 3552, 3554, 3568, 3580, 3583, 3593, 3596, 3608, 3614, 3617, 3630, 3633, 3646, 3648, 3649, 3652, 3655, 3656, 3658, 3660, 3662, 3675, 3676, 3678, 3681, 3689, 3693, 3696, 3701, 3703, 3708, 3715, 3725, 3730, 3756, 3757, 3766, 3778, 3781, 3786, 3791, 3792, 3799, 3807, 3813, 3814, 3815, 3825, 3828, 3834, 3846, 3850, 3857, 3860, 3862, 3865, 3877, 3878, 3882, 3884, 3888, 3892, 3901, 3902, 3906, 3907, 3908, 3918, 3920, 3922, 3923, 3933, 3950, 3955, 3959, 3961, 3963, 3964, 3966, 3968, 3975, 3977, 3984, 3986, 3990, 3995, 4001, 4008, 4015, 4025, 4029, 4038, 4039, 4045, 4055, 4056, 4057, 4064, 4068, 4070, 4074, 4076, 4081, 4082, 4086, 4087, 4089, 4093, 4107, 4112, 4113, 4114, 4119, 4124, 4130, 4160, 4161, 4171, 4173, 4183, 4185, 4189, 4190, 4196, 4202, 4204, 4208, 4213, 4217, 4231, 4235, 4242, 4250, 4257, 4261, 4263, 4265, 4272, 4280, 4295, 4300, 4307, 4313, 4322, 4326, 4337, 4338, 4341, 4344, 4346, 4348, 4356, 4358, 4359, 4363, 4367, 4371, 4373, 4374, 4391, 4394, 4397, 4402, 4404, 4409, 4424, 4426, 4431, 4432, 4440, 4443, 4444, 4445, 4446, 4456, 4462, 4463, 4464, 4466, 4467, 4470, 4473, 4474, 4485, 4486, 4490, 4491, 4494, 4496, 4505, 4518, 4523, 4524, 4536, 4537, 4538, 4547, 4550, 4554, 4560, 4561, 4573, 4575, 4578, 4583, 4589, 4592, 4595, 4630, 4634, 4635, 4636, 4637, 4642, 4648, 4649, 4652, 4655, 4657, 4661, 4665, 4667, 4675, 4678, 4683, 4695, 4696, 4697, 4703, 4714, 4722, 4744, 4745, 4748, 4749, 4750, 4757, 4758, 4762, 4768, 4780, 4783, 4787, 4789, 4796, 4798, 4800, 4811, 4816, 4821, 4825, 4841, 4842, 4843, 4845, 4846, 4848, 4854, 4860, 4866, 4867, 4880, 4894, 4916, 4919, 4920, 4922, 4924, 4928, 4931, 4932, 4938, 4943, 4946, 4957, 4958] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (train_idx, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(folds\u001b[38;5;241m.\u001b[39msplit(X_train, y_train)):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m폴드 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolds\u001b[38;5;241m.\u001b[39mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m     X_tr, y_tr \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[train_idx], \u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m     weights_tr \u001b[38;5;241m=\u001b[39m weights[train_idx]\n\u001b[0;32m     62\u001b[0m     d_train \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_tr, label\u001b[38;5;241m=\u001b[39my_tr, weight\u001b[38;5;241m=\u001b[39mweights_tr)\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1153\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1180\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[1;32m-> 1180\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1183\u001b[0m             \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1190\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thdco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[5, 9, 16, 17, 18, 22, 31, 33, 35, 41, 44, 50, 54, 56, 68, 69, 86, 93, 102, 104, 108, 116, 122, 124, 136, 138, 140, 149, 154, 158, 164, 168, 169, 177, 179, 180, 182, 188, 191, 192, 196, 210, 211, 214, 216, 218, 219, 228, 231, 234, 239, 241, 245, 256, 263, 282, 296, 309, 320, 331, 332, 333, 339, 341, 342, 350, 359, 362, 363, 370, 373, 374, 376, 385, 388, 401, 425, 430, 436, 439, 446, 450, 454, 471, 473, 479, 484, 490, 496, 497, 503, 505, 511, 517, 532, 533, 536, 538, 545, 550, 552, 553, 554, 561, 564, 568, 580, 601, 605, 619, 629, 630, 644, 652, 653, 668, 686, 698, 700, 706, 713, 721, 732, 745, 755, 765, 769, 786, 804, 810, 835, 836, 838, 839, 841, 843, 849, 853, 854, 871, 877, 878, 893, 896, 897, 926, 927, 930, 935, 946, 952, 960, 964, 972, 977, 983, 989, 994, 998, 1007, 1011, 1028, 1030, 1032, 1034, 1041, 1045, 1055, 1066, 1075, 1076, 1079, 1082, 1094, 1104, 1108, 1122, 1140, 1141, 1154, 1155, 1160, 1161, 1163, 1164, 1166, 1169, 1176, 1178, 1179, 1181, 1189, 1217, 1218, 1222, 1229, 1233, 1236, 1240, 1244, 1245, 1246, 1260, 1273, 1277, 1279, 1280, 1284, 1285, 1286, 1287, 1288, 1297, 1298, 1301, 1319, 1334, 1345, 1348, 1374, 1376, 1384, 1385, 1388, 1396, 1397, 1403, 1405, 1408, 1410, 1411, 1415, 1417, 1423, 1429, 1433, 1437, 1439, 1447, 1448, 1455, 1461, 1463, 1464, 1479, 1487, 1488, 1489, 1491, 1492, 1493, 1512, 1530, 1532, 1535, 1547, 1559, 1560, 1561, 1565, 1569, 1575, 1576, 1579, 1588, 1589, 1597, 1621, 1623, 1624, 1634, 1636, 1637, 1644, 1646, 1647, 1648, 1651, 1653, 1665, 1670, 1671, 1674, 1680, 1691, 1694, 1695, 1718, 1731, 1735, 1736, 1738, 1742, 1759, 1760, 1771, 1772, 1773, 1776, 1786, 1794, 1799, 1808, 1825, 1829, 1834, 1836, 1841, 1843, 1847, 1852, 1872, 1876, 1877, 1881, 1887, 1891, 1900, 1907, 1908, 1913, 1921, 1929, 1932, 1942, 1947, 1948, 1950, 1954, 1961, 1971, 1972, 1975, 1976, 1977, 1978, 1999, 2001, 2003, 2008, 2010, 2014, 2032, 2041, 2046, 2047, 2049, 2050, 2062, 2069, 2074, 2080, 2084, 2091, 2096, 2097, 2098, 2100, 2108, 2112, 2117, 2130, 2141, 2159, 2163, 2166, 2169, 2176, 2179, 2187, 2188, 2197, 2202, 2218, 2219, 2228, 2236, 2237, 2245, 2246, 2254, 2262, 2277, 2279, 2282, 2288, 2291, 2297, 2298, 2305, 2306, 2310, 2325, 2330, 2343, 2356, 2361, 2366, 2372, 2379, 2397, 2399, 2402, 2405, 2407, 2408, 2421, 2425, 2434, 2438, 2442, 2445, 2451, 2487, 2491, 2497, 2500, 2505, 2508, 2512, 2522, 2529, 2531, 2536, 2542, 2543, 2544, 2548, 2549, 2567, 2579, 2592, 2596, 2599, 2605, 2607, 2620, 2625, 2630, 2633, 2639, 2659, 2660, 2662, 2665, 2667, 2671, 2679, 2683, 2689, 2697, 2702, 2722, 2725, 2726, 2742, 2745, 2748, 2754, 2764, 2765, 2768, 2776, 2780, 2783, 2788, 2791, 2800, 2812, 2826, 2832, 2836, 2839, 2844, 2851, 2866, 2876, 2877, 2878, 2882, 2885, 2889, 2898, 2902, 2903, 2904, 2905, 2914, 2930, 2932, 2936, 2938, 2945, 2948, 2951, 2952, 2953, 2955, 2968, 2985, 2989, 2996, 3001, 3002, 3017, 3018, 3021, 3022, 3047, 3051, 3058, 3061, 3062, 3065, 3067, 3069, 3071, 3086, 3093, 3096, 3099, 3110, 3116, 3121, 3122, 3129, 3131, 3134, 3138, 3140, 3142, 3144, 3146, 3147, 3163, 3168, 3189, 3194, 3197, 3207, 3211, 3215, 3216, 3220, 3224, 3230, 3233, 3238, 3249, 3253, 3257, 3262, 3267, 3268, 3277, 3282, 3283, 3288, 3298, 3300, 3301, 3314, 3323, 3325, 3343, 3345, 3346, 3355, 3366, 3369, 3370, 3376, 3377, 3378, 3385, 3393, 3400, 3402, 3403, 3405, 3419, 3436, 3437, 3442, 3443, 3453, 3457, 3468, 3474, 3485, 3498, 3499, 3501, 3508, 3511, 3517, 3519, 3523, 3528, 3532, 3536, 3547, 3548, 3550, 3551, 3552, 3554, 3568, 3580, 3583, 3593, 3596, 3608, 3614, 3617, 3630, 3633, 3646, 3648, 3649, 3652, 3655, 3656, 3658, 3660, 3662, 3675, 3676, 3678, 3681, 3689, 3693, 3696, 3701, 3703, 3708, 3715, 3725, 3730, 3756, 3757, 3766, 3778, 3781, 3786, 3791, 3792, 3799, 3807, 3813, 3814, 3815, 3825, 3828, 3834, 3846, 3850, 3857, 3860, 3862, 3865, 3877, 3878, 3882, 3884, 3888, 3892, 3901, 3902, 3906, 3907, 3908, 3918, 3920, 3922, 3923, 3933, 3950, 3955, 3959, 3961, 3963, 3964, 3966, 3968, 3975, 3977, 3984, 3986, 3990, 3995, 4001, 4008, 4015, 4025, 4029, 4038, 4039, 4045, 4055, 4056, 4057, 4064, 4068, 4070, 4074, 4076, 4081, 4082, 4086, 4087, 4089, 4093, 4107, 4112, 4113, 4114, 4119, 4124, 4130, 4160, 4161, 4171, 4173, 4183, 4185, 4189, 4190, 4196, 4202, 4204, 4208, 4213, 4217, 4231, 4235, 4242, 4250, 4257, 4261, 4263, 4265, 4272, 4280, 4295, 4300, 4307, 4313, 4322, 4326, 4337, 4338, 4341, 4344, 4346, 4348, 4356, 4358, 4359, 4363, 4367, 4371, 4373, 4374, 4391, 4394, 4397, 4402, 4404, 4409, 4424, 4426, 4431, 4432, 4440, 4443, 4444, 4445, 4446, 4456, 4462, 4463, 4464, 4466, 4467, 4470, 4473, 4474, 4485, 4486, 4490, 4491, 4494, 4496, 4505, 4518, 4523, 4524, 4536, 4537, 4538, 4547, 4550, 4554, 4560, 4561, 4573, 4575, 4578, 4583, 4589, 4592, 4595, 4630, 4634, 4635, 4636, 4637, 4642, 4648, 4649, 4652, 4655, 4657, 4661, 4665, 4667, 4675, 4678, 4683, 4695, 4696, 4697, 4703, 4714, 4722, 4744, 4745, 4748, 4749, 4750, 4757, 4758, 4762, 4768, 4780, 4783, 4787, 4789, 4796, 4798, 4800, 4811, 4816, 4821, 4825, 4841, 4842, 4843, 4845, 4846, 4848, 4854, 4860, 4866, 4867, 4880, 4894, 4916, 4919, 4920, 4922, 4924, 4928, 4931, 4932, 4938, 4943, 4946, 4957, 4958] not in index'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import joblib\n",
    "# 기본 설정\n",
    "X_train = X_encoded\n",
    "y_train = y_subclass\n",
    "random_states = [0, 22, 42, 1215]  # 사용할 random_state 값들\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "all_macro_f1_scores = []\n",
    "all_class_f1_scores = []\n",
    "all_feature_importances = []\n",
    "\n",
    "# 테스트 데이터 예측 결과 저장용 배열 초기화\n",
    "final_lgb_test_preds_proba = np.zeros((test_X_encoded.shape[0], len(np.unique(y_train))))\n",
    "\n",
    "# 다양한 random_state로 반복\n",
    "for r_state in random_states:\n",
    "    print(f\"## Random State: {r_state} ##\\n\")\n",
    "    \n",
    "    # Stratified K-Fold 설정\n",
    "    folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=r_state)\n",
    "\n",
    "    # LightGBM 모델 파라미터 설정\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(np.unique(y_train)),\n",
    "        'learning_rate': 0.01786236294491012,\n",
    "        'random_state': 42,\n",
    "        'metric': 'multi_logloss',\n",
    "        'early_stopping_rounds': 100,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'num_leaves': 31,\n",
    "        'min_data_in_leaf': 27,\n",
    "        'lambda_l1': 0.00046641762342032746,\n",
    "        'lambda_l2': 8.228074508440626e-06,\n",
    "        'min_split_gain': 0.0008507877755254931,\n",
    "        'min_child_weight': 0.00044655605235435\n",
    "    }\n",
    "\n",
    "    # F1 스코어 및 중요도 저장용 리스트 초기화\n",
    "    macro_f1_score_list = []\n",
    "    feature_importance_list = []\n",
    "    class_f1_scores = []\n",
    "\n",
    "    # 각 클래스의 샘플 수 계산\n",
    "    class_counts = np.bincount(y_train)\n",
    "    total_samples = len(y_train)\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "\n",
    "    # 가중치 배열 생성\n",
    "    weights = np.array([class_weights[label] for label in y_train])\n",
    "\n",
    "    for idx, (train_idx, _) in enumerate(folds.split(X_train, y_train)):\n",
    "        print('#' * 40, f'폴드 {idx+1} / {folds.n_splits}', \"#\" * 40)\n",
    "        X_tr, y_tr = X_train.iloc[train_idx], y_train[train_idx]\n",
    "        weights_tr = weights[train_idx]\n",
    "        \n",
    "        d_train = lgb.Dataset(X_tr, label=y_tr, weight=weights_tr)\n",
    "        d_valid = lgb.Dataset(val_x_encoded, label=val_y_encoded, reference=d_train)\n",
    "        \n",
    "        lgb_model = lgb.train(params=params,\n",
    "                              train_set=d_train,\n",
    "                              num_boost_round=2000,\n",
    "                              valid_sets=[d_train, d_valid])\n",
    "        \n",
    "        # 테스트 데이터 예측 (여러 random_state 결과를 평균)\n",
    "        final_lgb_test_preds_proba += lgb_model.predict(test_X_encoded, num_iteration=lgb_model.best_iteration) / (len(random_states)*folds.n_splits)\n",
    "        \n",
    "        # 검증 데이터 예측\n",
    "        val_preds_proba = lgb_model.predict(val_x_encoded, num_iteration=lgb_model.best_iteration)\n",
    "        val_preds = np.argmax(val_preds_proba, axis=1)\n",
    "        model_path = os.path.join(file_path + \"./xgb_model_path\", f\"xgb_model_rs{r_state}_fold{idx+1}.joblib\")\n",
    "        joblib.dump(lgb_model, model_path)\n",
    "        print(f\"모델이 '{model_path}'에 저장되었습니다.\\n\")            \n",
    "        \n",
    "        # 다중 클래스 F1 스코어 계산 (클래스별 F1 스코어 포함)\n",
    "        macro_f1 = f1_score(val_y_encoded, val_preds, average='macro')\n",
    "        class_f1 = f1_score(val_y_encoded, val_preds, average=None)\n",
    "        macro_f1_score_list.append(macro_f1)\n",
    "        class_f1_scores.append(class_f1)\n",
    "        \n",
    "        print(f'폴드 {idx+1} Macro F1 score: {macro_f1}\\n')\n",
    "        print(f'폴드 {idx+1} 클래스별 F1 score:\\n{classification_report(val_y_encoded, val_preds)}\\n')\n",
    "        \n",
    "        feature_importance_list.append(lgb_model.feature_importance())\n",
    "\n",
    "    # 각 random_state에 대한 결과 저장\n",
    "    avg_macro_f1 = np.mean(macro_f1_score_list)\n",
    "    all_macro_f1_scores.append(avg_macro_f1)\n",
    "    all_class_f1_scores.append(class_f1_scores)\n",
    "    all_feature_importances.append(feature_importance_list)\n",
    "\n",
    "    print(f'Random State {r_state} 검증 평균 Macro F1 score: {avg_macro_f1}\\n')\n",
    "\n",
    "# 전체 결과 요약\n",
    "for i, r_state in enumerate(random_states):\n",
    "    print(f\"## Random State {r_state} 결과 ##\")\n",
    "    print(f\"검증 평균 Macro F1 score: {all_macro_f1_scores[i]}\")\n",
    "    print(f\"클래스별 F1 score:\\n{np.mean(all_class_f1_scores[i], axis=0)}\\n\")\n",
    "    print(\"#\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.drop(columns=['ID'])\n",
    "test_X_encoded = test_X.copy()\n",
    "test_X_encoded[categorical_columns] = ordinal_encoder.transform(test_X[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = le_subclass.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson = pd.read_csv(\"./sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson[\"SUBCLASS\"] = original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisson.to_csv('./baseline_submission_lgb_OOF.csv', encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# SUBCLASS 가 범주형이기 때문에 LabelEncoder 사용\n",
    "le_subclass = LabelEncoder()\n",
    "train['SUBCLASS'] = le_subclass.fit_transform(train['SUBCLASS'])\n",
    "\n",
    "# 변환된 레이블 확인\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"원래 레이블: {label}, 변환된 숫자: {i}\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train = train.drop(columns=\"SUBCLASS\"), train[\"SUBCLASS\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "\n",
    "train_all = pd.concat((X_train, y_train), axis=1)\n",
    "val_all = pd.concat((X_val, y_val), axis=1)\n",
    "\n",
    "## x 의 경우도 범주형으로 구성되어 있어, 알맞은 인코딩 필요\n",
    "X = train_all.drop(columns=['SUBCLASS', 'ID'])\n",
    "y_subclass = train_all['SUBCLASS']\n",
    "\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_encoded = X.copy()\n",
    "X_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "\n",
    "test_X = test.drop(columns=['ID'])\n",
    "test_X_encoded = test_X.copy()\n",
    "test_X_encoded[categorical_columns] = ordinal_encoder.transform(test_X[categorical_columns])\n",
    "\n",
    "X_val = val_all.drop(columns=['SUBCLASS', 'ID'])\n",
    "val_y_encoded = val_all['SUBCLASS']\n",
    "\n",
    "\n",
    "val_x_encoded = X_val.copy()\n",
    "val_x_encoded[categorical_columns] = ordinal_encoder.transform(X_val[categorical_columns])\n",
    "\n",
    "file_path = ''\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import joblib\n",
    "# 기본 설정\n",
    "X_train = X_encoded\n",
    "y_train = y_subclass\n",
    "random_states = [0, 22, 42, 1215]  # 사용할 random_state 값들\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "all_macro_f1_scores = []\n",
    "all_class_f1_scores = []\n",
    "all_feature_importances = []\n",
    "\n",
    "# 테스트 데이터 예측 결과 저장용 배열 초기화\n",
    "final_lgb_test_preds_proba = np.zeros((test_X_encoded.shape[0], len(np.unique(y_train))))\n",
    "\n",
    "# 다양한 random_state로 반복\n",
    "for r_state in random_states:\n",
    "    print(f\"## Random State: {r_state} ##\\n\")\n",
    "    \n",
    "    # Stratified K-Fold 설정\n",
    "    folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=r_state)\n",
    "\n",
    "    # LightGBM 모델 파라미터 설정\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(np.unique(y_train)),\n",
    "        'learning_rate': 0.01786236294491012,\n",
    "        'random_state': 42,\n",
    "        'metric': 'multi_logloss',\n",
    "        'early_stopping_rounds': 100,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'num_leaves': 31,\n",
    "        'min_data_in_leaf': 27,\n",
    "        'lambda_l1': 0.00046641762342032746,\n",
    "        'lambda_l2': 8.228074508440626e-06,\n",
    "        'min_split_gain': 0.0008507877755254931,\n",
    "        'min_child_weight': 0.00044655605235435\n",
    "    }\n",
    "\n",
    "    # F1 스코어 및 중요도 저장용 리스트 초기화\n",
    "    macro_f1_score_list = []\n",
    "    feature_importance_list = []\n",
    "    class_f1_scores = []\n",
    "\n",
    "    # 각 클래스의 샘플 수 계산\n",
    "    class_counts = np.bincount(y_train)\n",
    "    total_samples = len(y_train)\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "\n",
    "    # 가중치 배열 생성\n",
    "    weights = np.array([class_weights[label] for label in y_train])\n",
    "\n",
    "    for idx, (train_idx, _) in enumerate(folds.split(X_train, y_train)):\n",
    "        print('#' * 40, f'폴드 {idx+1} / {folds.n_splits}', \"#\" * 40)\n",
    "        X_tr, y_tr = X_train.iloc[train_idx], y_train[train_idx]\n",
    "        weights_tr = weights[train_idx]\n",
    "        \n",
    "        d_train = lgb.Dataset(X_tr, label=y_tr, weight=weights_tr)\n",
    "        d_valid = lgb.Dataset(val_x_encoded, label=val_y_encoded, reference=d_train)\n",
    "        \n",
    "        lgb_model = lgb.train(params=params,\n",
    "                              train_set=d_train,\n",
    "                              num_boost_round=2000,\n",
    "                              valid_sets=[d_train, d_valid])\n",
    "        \n",
    "        # 테스트 데이터 예측 (여러 random_state 결과를 평균)\n",
    "        final_lgb_test_preds_proba += lgb_model.predict(test_X_encoded, num_iteration=lgb_model.best_iteration) / (len(random_states)*folds.n_splits)\n",
    "        \n",
    "        # 검증 데이터 예측\n",
    "        val_preds_proba = lgb_model.predict(val_x_encoded, num_iteration=lgb_model.best_iteration)\n",
    "        val_preds = np.argmax(val_preds_proba, axis=1)\n",
    "        model_path = os.path.join(file_path + \"./xgb_model_path\", f\"xgb_model_rs{r_state}_fold{idx+1}.joblib\")\n",
    "        joblib.dump(lgb_model, model_path)\n",
    "        print(f\"모델이 '{model_path}'에 저장되었습니다.\\n\")            \n",
    "        \n",
    "        # 다중 클래스 F1 스코어 계산 (클래스별 F1 스코어 포함)\n",
    "        macro_f1 = f1_score(val_y_encoded, val_preds, average='macro')\n",
    "        class_f1 = f1_score(val_y_encoded, val_preds, average=None)\n",
    "        macro_f1_score_list.append(macro_f1)\n",
    "        class_f1_scores.append(class_f1)\n",
    "        \n",
    "        print(f'폴드 {idx+1} Macro F1 score: {macro_f1}\\n')\n",
    "        print(f'폴드 {idx+1} 클래스별 F1 score:\\n{classification_report(val_y_encoded, val_preds)}\\n')\n",
    "        \n",
    "        feature_importance_list.append(lgb_model.feature_importance())\n",
    "\n",
    "    # 각 random_state에 대한 결과 저장\n",
    "    avg_macro_f1 = np.mean(macro_f1_score_list)\n",
    "    all_macro_f1_scores.append(avg_macro_f1)\n",
    "    all_class_f1_scores.append(class_f1_scores)\n",
    "    all_feature_importances.append(feature_importance_list)\n",
    "\n",
    "    print(f'Random State {r_state} 검증 평균 Macro F1 score: {avg_macro_f1}\\n')\n",
    "\n",
    "# 전체 결과 요약\n",
    "for i, r_state in enumerate(random_states):\n",
    "    print(f\"## Random State {r_state} 결과 ##\")\n",
    "    print(f\"검증 평균 Macro F1 score: {all_macro_f1_scores[i]}\")\n",
    "    print(f\"클래스별 F1 score:\\n{np.mean(all_class_f1_scores[i], axis=0)}\\n\")\n",
    "    print(\"#\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
